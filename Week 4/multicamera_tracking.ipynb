{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "from sort import Sort\n",
    "import os, copy\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition remains the same\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, sequence):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights='ResNet50_Weights.DEFAULT')\n",
    "        self.model.fc = nn.Identity()\n",
    "        self.sequence = sequence\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def get_embedding(self, bbox, frame_num, camera_id):\n",
    "\n",
    "        name = 'vdo10.avi' if camera_id == 'c015' else 'vdo.avi'\n",
    "        path = f\"aic19-track1-mtmc-train/train/{self.sequence}/{camera_id}/{name}\"\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "        ret, frame = cap.read()\n",
    "        cap.release()\n",
    "        frame = frame[bbox[1]:bbox[3], bbox[0]:bbox[2]]\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = torch.tensor((cv2.resize(frame, (224, 224)) / 255.0).transpose(2, 0, 1), dtype=torch.float32).unsqueeze(0).cuda()\n",
    "        return self.model(frame)[0].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths = ['aic19-track1-mtmc-train/train/S01/c001/vdo.avi', \n",
    "               'aic19-track1-mtmc-train/train/S01/c002/vdo.avi', \n",
    "               'aic19-track1-mtmc-train/train/S01/c003/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S01/c004/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S01/c005/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c010/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c011/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c012/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c013/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c014/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c015/vdo10.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c016/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c017/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c018/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c019/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c020/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c021/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c022/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c023/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c024/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c025/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c026/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c027/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c028/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c029/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c030/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c031/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c032/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c033/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c034/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c035/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c036/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c037/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c038/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c039/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c040/vdo.avi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_fps(input_path, output_path, input_fps=8, target_fps=10):\n",
    "    \"\"\"\n",
    "    This function upscales the FPS of a video by interpolating frames using OpenCV and NumPy.\n",
    "    \n",
    "    Parameters:\n",
    "    input_path (str): The path to the input video file.\n",
    "    output_path (str): The path where the output video will be saved.\n",
    "    input_fps (int): The original FPS of the video.\n",
    "    target_fps (int): The target FPS to upscale the video to.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Capture video from input path\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        return \"Failed to open video file.\"\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, target_fps, (width, height))\n",
    "    \n",
    "    prev_frame = None\n",
    "    success, frame = cap.read()\n",
    "    while success:\n",
    "        out.write(frame)  # Write the original frame\n",
    "        \n",
    "        # If there's a previous frame, generate interpolated frames\n",
    "        if prev_frame is not None:\n",
    "            # Generate interpolated frames\n",
    "            for _ in range((target_fps // input_fps) - 1):\n",
    "                interp_frame = cv2.addWeighted(prev_frame, 0.5, frame, 0.5, 0)\n",
    "                out.write(interp_frame)\n",
    "                \n",
    "        prev_frame = frame\n",
    "        success, frame = cap.read()\n",
    "        \n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    return \"Video FPS upscaled successfully.\"\n",
    "\n",
    "# upscale_fps('aic19-track1-mtmc-train/train/S03/c015/vdo.avi', 'aic19-track1-mtmc-train/train/S03/c015/vdo10.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_detections(video_path, yolo):\n",
    "    \"\"\"\n",
    "    Given a video, create detections for each frame in the video and store bounding boxes in a text file\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Create a text file to store the bounding boxes\n",
    "    f = open(f\"detections/{video_path.split('/')[-2].split('.')[0]}.txt\", \"w\")\n",
    "\n",
    "    frame_num = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Get the detections for the frame\n",
    "        detections = yolo(frame, verbose=False)\n",
    "\n",
    "        # Write the bounding boxes to the text file\n",
    "        for box in detections[0].boxes:\n",
    "            if box.cls == 2:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].int().tolist()\n",
    "                f.write(f\"{frame_num},{x1},{y1},{x2},{y2}\\n\")\n",
    "\n",
    "        frame_num += 1\n",
    "\n",
    "    f.close()\n",
    "    cap.release()\n",
    "\n",
    "# for video in tqdm(video_paths):\n",
    "#     create_detections(video, yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lgudino/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Computing trackings: 100%|██████████| 6/6 [00:19<00:00,  3.23s/it]\n"
     ]
    }
   ],
   "source": [
    "def convert_detections_to_sort_format(detections):\n",
    "    \"\"\"\n",
    "    Convert detections to the format expected by the SORT algorithm. Stacks all the detections of the same frame into a single array.\n",
    "    \"\"\"\n",
    "    max_frame = detections[-1][0]\n",
    "    all_detections = []\n",
    "    for frame_num in range(max_frame + 1):\n",
    "        frame_detections = [d[1:] + [1] for d in detections if d[0] == frame_num]\n",
    "        if len(frame_detections) == 0:\n",
    "            # print(f\"No detections found for frame {frame_num}\")\n",
    "            frame_detections = np.empty((0, 5))\n",
    "        all_detections.append(frame_detections)\n",
    "    return all_detections\n",
    "\n",
    "def compute_similarity(embedding1, embedding2):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between two embeddings.\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(embedding1 - embedding2)\n",
    "\n",
    "sequence = 'S03'\n",
    "if sequence == 'S01':\n",
    "    camera_ids = ['c001', 'c002', 'c003', 'c004', 'c005']\n",
    "elif sequence == 'S03':\n",
    "    camera_ids = ['c010', 'c011', 'c012', 'c013', 'c014', 'c015']\n",
    "elif sequence == 'S04':\n",
    "    camera_ids = ['c016', 'c017', 'c018', 'c019', 'c020', 'c021', 'c022', 'c023', 'c024', 'c025', 'c026', 'c027', 'c028', 'c029', 'c030', 'c031', 'c032', 'c033', 'c034', 'c035', 'c036', 'c037', 'c038', 'c039', 'c040']\n",
    "\n",
    "siamese_net = Net(sequence).cuda().eval()\n",
    "siamese_net.load_state_dict(torch.load('siamese_model_6.pth', map_location=torch.device('cuda')))\n",
    "# yolo = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Load detections from text files\n",
    "detections = {}\n",
    "for camera_id in camera_ids:\n",
    "    with open(f'detections/{camera_id}.txt', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        detections[camera_id] = [[int(x) for x in line.strip().split(',')] for line in lines]\n",
    "\n",
    "# Compute single trackings for each camera\n",
    "trackings = {c_id: [] for c_id in camera_ids}\n",
    "for camera_id, dets in tqdm(detections.items(), desc=\"Computing trackings\"):\n",
    "    dets_sort = convert_detections_to_sort_format(dets)#[:150]\n",
    "    mot_tracker = Sort()\n",
    "    for frame_num, frame_dets in enumerate(dets_sort):\n",
    "        d = mot_tracker.update(np.array(frame_dets)).astype(int)\n",
    "        d = [[max(0, x) for x in det] for det in d]\n",
    "        trackings[camera_id].append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pre-compute all embeddings for each detection in every camera and frame\n",
    "# precomputed_embeddings = {}\n",
    "# for cam_id in camera_ids:\n",
    "#     precomputed_embeddings[cam_id] = {}\n",
    "#     for frame, detections in tqdm(enumerate(trackings[cam_id]), desc=f\"Precomputing embeddings for {cam_id}\", total=len(trackings[cam_id])):\n",
    "#         with torch.no_grad():\n",
    "#             precomputed_embeddings[cam_id][frame] = [\n",
    "#                 siamese_net.get_embedding(det[:4], frame, cam_id) for det in detections\n",
    "#             ]\n",
    "\n",
    "# with open('precomputed_embeddings.pkl', 'wb') as f:\n",
    "#     pickle.dump(precomputed_embeddings, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('precomputed_embeddings_s03.pkl', 'rb') as f:\n",
    "    precomputed_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing c010 with all other cameras:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Comparing c010 with all other cameras: 100%|██████████| 5/5 [04:26<00:00, 53.30s/it]\n",
      "Comparing c011 with all other cameras: 100%|██████████| 4/4 [04:55<00:00, 73.90s/it]\n",
      "Comparing c012 with all other cameras: 100%|██████████| 3/3 [02:26<00:00, 48.81s/it]\n",
      "Comparing c013 with all other cameras: 100%|██████████| 2/2 [00:29<00:00, 14.82s/it]\n",
      "Comparing c014 with all other cameras: 100%|██████████| 1/1 [01:29<00:00, 89.86s/it]\n",
      "Comparing c015 with all other cameras: 0it [00:00, ?it/s]\n",
      "Updating global trackings for c010 and c011: 100%|██████████| 4736/4736 [00:01<00:00, 4604.72it/s]\n",
      "Updating global trackings for c010 and c012: 100%|██████████| 397/397 [00:00<00:00, 4041.02it/s]\n",
      "Updating global trackings for c010 and c014: 100%|██████████| 3687/3687 [00:00<00:00, 4732.31it/s]\n",
      "Updating global trackings for c010 and c015: 100%|██████████| 3374/3374 [00:00<00:00, 5779.62it/s]\n",
      "Updating global trackings for c010 and c013: 100%|██████████| 325/325 [00:00<00:00, 3449.10it/s]\n",
      "Updating global trackings for c011 and c015: 100%|██████████| 7679/7679 [00:01<00:00, 5908.18it/s]\n",
      "Updating global trackings for c011 and c014: 100%|██████████| 6317/6317 [00:01<00:00, 4613.52it/s]\n",
      "Updating global trackings for c011 and c012: 100%|██████████| 3123/3123 [00:00<00:00, 4348.23it/s]\n",
      "Updating global trackings for c011 and c013: 100%|██████████| 2134/2134 [00:00<00:00, 3891.98it/s]\n",
      "Updating global trackings for c012 and c015: 100%|██████████| 3119/3119 [00:00<00:00, 5832.02it/s]\n",
      "Updating global trackings for c012 and c014: 100%|██████████| 7682/7682 [00:01<00:00, 4876.20it/s]\n",
      "Updating global trackings for c012 and c013: 100%|██████████| 2317/2317 [00:00<00:00, 4147.08it/s]\n",
      "Updating global trackings for c013 and c014: 100%|██████████| 1917/1917 [00:00<00:00, 3948.79it/s]\n",
      "Updating global trackings for c013 and c015: 100%|██████████| 791/791 [00:00<00:00, 5505.82it/s]\n",
      "Updating global trackings for c014 and c015: 100%|██████████| 12302/12302 [00:02<00:00, 5915.30it/s]\n"
     ]
    }
   ],
   "source": [
    "matches = {}\n",
    "# Initialize a dictionary to track the best match for each detection across all cameras and frames\n",
    "best_matches = {cam_id: {frame: {} for frame in range(len(trackings[cam_id]))} for cam_id in camera_ids}\n",
    "\n",
    "for i, cam1 in enumerate(camera_ids):\n",
    "    for j, cam2 in tqdm(enumerate(camera_ids[i+1:]), desc=f\"Comparing {cam1} with all other cameras\", total=len(camera_ids) - i - 1):\n",
    "        if cam1 == cam2:\n",
    "            continue  # Skip comparing the camera with itself\n",
    "\n",
    "        for frame1, detections1 in enumerate(trackings[cam1]):\n",
    "            for frame2, detections2 in enumerate(trackings[cam2]):\n",
    "                if abs(frame1 - frame2) > 70:\n",
    "                    if frame1 < frame2:\n",
    "                        break\n",
    "                    else:\n",
    "                        continue\n",
    "\n",
    "                for idx1, det1 in enumerate(detections1):\n",
    "                    for idx2, det2 in enumerate(detections2):\n",
    "                        embedding1 = precomputed_embeddings[cam1][frame1][idx1]\n",
    "                        embedding2 = precomputed_embeddings[cam2][frame2][idx2]\n",
    "                        similarity = compute_similarity(embedding1, embedding2)\n",
    "\n",
    "                        current_best = best_matches[cam1][frame1].get(idx1, (None, None, float('inf'), None, None))\n",
    "                        _, _, current_best_similarity, _, _ = current_best\n",
    "\n",
    "                        if similarity < current_best_similarity and similarity < 7:\n",
    "                            best_matches[cam1][frame1][idx1] = (cam2, frame2, similarity, idx2, det2)\n",
    "\n",
    "for cam1, frames in best_matches.items():\n",
    "    for frame1, detections in frames.items():\n",
    "        for idx1, (cam2, frame2, _, idx2, det2) in detections.items():\n",
    "            if cam2 is None:\n",
    "                continue  # No match found for this detection\n",
    "            if (cam1, cam2) not in matches:\n",
    "                matches[(cam1, cam2)] = []\n",
    "            det1 = trackings[cam1][frame1][idx1]\n",
    "            matches[(cam1, cam2)].append((frame1, frame2, det1, det2))\n",
    "\n",
    "trackings_global = copy.deepcopy(trackings)\n",
    "for (cam1, cam2), match_list in matches.items():\n",
    "    for frame1, frame2, det1, det2 in tqdm(match_list, desc=f\"Updating global trackings for {cam1} and {cam2}\"):\n",
    "\n",
    "        for frame_num, bbox_local in enumerate(trackings[cam2]):\n",
    "            if frame2 == frame_num:\n",
    "                for idx,bbox in enumerate(trackings[cam2][frame2]):\n",
    "                    if bbox[-1] == det2[-1]:\n",
    "                        break\n",
    "\n",
    "                for idx2,bbox in enumerate(trackings[cam1][frame1]):\n",
    "                    if bbox[-1] == det1[-1]:\n",
    "                        break\n",
    "                \n",
    "                # print(cam1, frame1, idx2, cam2, frame2, idx)\n",
    "                trackings_global[cam1][frame1][idx2][-1] = trackings[cam2][frame2][idx][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tracking(video_path, camera_id, trackings_global, output_path):\n",
    "    \"\"\"\n",
    "    Visualize tracking by drawing bounding boxes and track IDs on video frames for a specific camera.\n",
    "\n",
    "    Parameters:\n",
    "    - video_path: Path to the video file for the camera.\n",
    "    - camera_id: ID of the camera to visualize detections for.\n",
    "    - global_tracks: List of global tracks, each containing detections from multiple cameras.\n",
    "    - output_path: Path to save the output video with tracking visualization.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return\n",
    "\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'MP4V'), frame_rate, (frame_width, frame_height))\n",
    "\n",
    "    for frame_number in tqdm(range(0, 200)):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Iterate through all tracks and their detections\n",
    "        for bbox in trackings_global[camera_id][frame_number]:\n",
    "            x1, y1, x2, y2, track_id = bbox\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 127, 0), 2)\n",
    "            cv2.putText(frame, str(track_id), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 127, 0), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Load the video\n",
    "for c in range(0, len(camera_ids)):\n",
    "    video_path = video_paths[5+c]\n",
    "    camera_id = video_path.split('/')[-2]\n",
    "    output_path = f'tracking_output_{camera_id}.mp4' \n",
    "    visualize_tracking(video_path, camera_id, trackings_global, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder values for <conf>, <x>, <y>, <z> since these are not provided\n",
    "conf, x, y, z = 1, -1, -1, -1  # Using -1 to indicate unknown or not applicable\n",
    "\n",
    "for cam in camera_ids:\n",
    "(14.098+4.088+8.259)\n",
    "    # Convert data to the required gt.txt format\n",
    "    gt_content = []\n",
    "    for frame, bboxes in enumerate(trackings_global[cam]):\n",
    "        s = set()\n",
    "        for bbox in bboxes:\n",
    "            bb_left, bb_top, bb_right, bb_bottom, obj_id = map(int, bbox)\n",
    "            if obj_id in s:\n",
    "                continue\n",
    "            s.add(obj_id)\n",
    "            bb_width = bb_right - bb_left\n",
    "            bb_height = bb_bottom - bb_top\n",
    "            gt_content.append(f\"{frame+1}, {obj_id}, {bb_left}, {bb_top}, {bb_width}, {bb_height}, {conf}, {x}, {y}, {z}\")\n",
    "\n",
    "    # Join all entries to form the final content for the gt.txt file\n",
    "    gt_text = \"\\n\".join(gt_content)\n",
    "\n",
    "    file_path = f'TrackEval/data/trackers/mot_challenge/parabellum-s04-train/metric_learning/data/s04_{cam}.txt'  # Define the file path\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(gt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error importing BURST due to missing underlying dependency: No module named 'pycocotools'\n",
      "\n",
      "Eval Config:\n",
      "USE_PARALLEL         : False                         \n",
      "NUM_PARALLEL_CORES   : 8                             \n",
      "BREAK_ON_ERROR       : True                          \n",
      "RETURN_ON_ERROR      : False                         \n",
      "LOG_ON_ERROR         : /mnt/DATA/lgudino/C6/mcv-c6-2024-team4/Week 4/TrackEval/error_log.txt\n",
      "PRINT_RESULTS        : True                          \n",
      "PRINT_ONLY_COMBINED  : False                         \n",
      "PRINT_CONFIG         : True                          \n",
      "TIME_PROGRESS        : True                          \n",
      "DISPLAY_LESS_PROGRESS : False                         \n",
      "OUTPUT_SUMMARY       : True                          \n",
      "OUTPUT_EMPTY_CLASSES : True                          \n",
      "OUTPUT_DETAILED      : True                          \n",
      "PLOT_CURVES          : True                          \n",
      "\n",
      "MotChallenge2DBox Config:\n",
      "PRINT_CONFIG         : True                          \n",
      "GT_FOLDER            : /mnt/DATA/lgudino/C6/mcv-c6-2024-team4/Week 4/TrackEval/data/gt/mot_challenge/\n",
      "TRACKERS_FOLDER      : /mnt/DATA/lgudino/C6/mcv-c6-2024-team4/Week 4/TrackEval/data/trackers/mot_challenge/\n",
      "OUTPUT_FOLDER        : None                          \n",
      "TRACKERS_TO_EVAL     : ['metric_learning']           \n",
      "CLASSES_TO_EVAL      : ['pedestrian']                \n",
      "BENCHMARK            : parabellum-s04                \n",
      "SPLIT_TO_EVAL        : train                         \n",
      "INPUT_AS_ZIP         : False                         \n",
      "DO_PREPROC           : False                         \n",
      "TRACKER_SUB_FOLDER   : data                          \n",
      "OUTPUT_SUB_FOLDER    :                               \n",
      "TRACKER_DISPLAY_NAMES : None                          \n",
      "SEQMAP_FOLDER        : None                          \n",
      "SEQMAP_FILE          : None                          \n",
      "SEQ_INFO             : None                          \n",
      "GT_LOC_FORMAT        : {gt_folder}/{seq}/gt/gt.txt   \n",
      "SKIP_SPLIT_FOL       : False                         \n",
      "\n",
      "Identity Config:\n",
      "METRICS              : ['HOTA', 'Identity']          \n",
      "THRESHOLD            : 0.5                           \n",
      "PRINT_CONFIG         : True                          \n",
      "\n",
      "Evaluating 1 tracker(s) on 26 sequence(s) for 1 class(es) on MotChallenge2DBox dataset using the following metrics: HOTA, Identity, Count\n",
      "\n",
      "\n",
      "Evaluating metric_learning\n",
      "\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c016)          0.1790 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.2086 sec\n",
      "    HOTA.eval_sequence()                                                   0.1558 sec\n",
      "    Identity.eval_sequence()                                               0.0323 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "1 eval_sequence(s04_c016, metric_learning)                               0.5871 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c017)          0.1716 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1845 sec\n",
      "    HOTA.eval_sequence()                                                   0.1548 sec\n",
      "    Identity.eval_sequence()                                               0.0384 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "2 eval_sequence(s04_c017, metric_learning)                               0.5611 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c018)          0.1652 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1862 sec\n",
      "    HOTA.eval_sequence()                                                   0.1487 sec\n",
      "    Identity.eval_sequence()                                               0.0335 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "3 eval_sequence(s04_c018, metric_learning)                               0.5434 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c019)          0.1579 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1995 sec\n",
      "    HOTA.eval_sequence()                                                   0.1854 sec\n",
      "    Identity.eval_sequence()                                               0.0341 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "4 eval_sequence(s04_c019, metric_learning)                               0.5888 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c020)          0.1928 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1971 sec\n",
      "    HOTA.eval_sequence()                                                   0.1271 sec\n",
      "    Identity.eval_sequence()                                               0.0294 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "5 eval_sequence(s04_c020, metric_learning)                               0.5596 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c020)          0.1531 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1947 sec\n",
      "    HOTA.eval_sequence()                                                   0.1735 sec\n",
      "    Identity.eval_sequence()                                               0.0338 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "6 eval_sequence(s04_c020, metric_learning)                               0.5660 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c021)          0.1598 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1857 sec\n",
      "    HOTA.eval_sequence()                                                   0.1605 sec\n",
      "    Identity.eval_sequence()                                               0.0316 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "7 eval_sequence(s04_c021, metric_learning)                               0.5486 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c022)          0.1733 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1915 sec\n",
      "    HOTA.eval_sequence()                                                   0.1665 sec\n",
      "    Identity.eval_sequence()                                               0.0463 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "8 eval_sequence(s04_c022, metric_learning)                               0.5922 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c023)          0.1935 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.2105 sec\n",
      "    HOTA.eval_sequence()                                                   0.1578 sec\n",
      "    Identity.eval_sequence()                                               0.0359 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "9 eval_sequence(s04_c023, metric_learning)                               0.6094 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c024)          0.1522 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1882 sec\n",
      "    HOTA.eval_sequence()                                                   0.1147 sec\n",
      "    Identity.eval_sequence()                                               0.0338 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "10 eval_sequence(s04_c024, metric_learning)                               0.4979 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c025)          0.1685 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.2053 sec\n",
      "    HOTA.eval_sequence()                                                   0.2025 sec\n",
      "    Identity.eval_sequence()                                               0.0446 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "11 eval_sequence(s04_c025, metric_learning)                               0.6367 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c026)          0.2050 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.2084 sec\n",
      "    HOTA.eval_sequence()                                                   0.2029 sec\n",
      "    Identity.eval_sequence()                                               0.0414 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "12 eval_sequence(s04_c026, metric_learning)                               0.6706 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c027)          0.1856 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1966 sec\n",
      "    HOTA.eval_sequence()                                                   0.1575 sec\n",
      "    Identity.eval_sequence()                                               0.0342 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "13 eval_sequence(s04_c027, metric_learning)                               0.5821 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c028)          0.1715 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.2067 sec\n",
      "    HOTA.eval_sequence()                                                   0.1171 sec\n",
      "    Identity.eval_sequence()                                               0.0306 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "14 eval_sequence(s04_c028, metric_learning)                               0.5379 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c029)          0.1689 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1964 sec\n",
      "    HOTA.eval_sequence()                                                   0.1819 sec\n",
      "    Identity.eval_sequence()                                               0.0310 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "15 eval_sequence(s04_c029, metric_learning)                               0.5851 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c030)          0.1750 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.2118 sec\n",
      "    HOTA.eval_sequence()                                                   0.1976 sec\n",
      "    Identity.eval_sequence()                                               0.0392 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "16 eval_sequence(s04_c030, metric_learning)                               0.6306 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c031)          0.2263 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1969 sec\n",
      "    HOTA.eval_sequence()                                                   0.1328 sec\n",
      "    Identity.eval_sequence()                                               0.0387 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "17 eval_sequence(s04_c031, metric_learning)                               0.6060 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c032)          0.1760 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1902 sec\n",
      "    HOTA.eval_sequence()                                                   0.1792 sec\n",
      "    Identity.eval_sequence()                                               0.0381 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "18 eval_sequence(s04_c032, metric_learning)                               0.5896 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c033)          0.1608 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.2019 sec\n",
      "    HOTA.eval_sequence()                                                   0.1611 sec\n",
      "    Identity.eval_sequence()                                               0.0346 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "19 eval_sequence(s04_c033, metric_learning)                               0.5677 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c034)          0.1679 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.2145 sec\n",
      "    HOTA.eval_sequence()                                                   0.1855 sec\n",
      "    Identity.eval_sequence()                                               0.0327 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "20 eval_sequence(s04_c034, metric_learning)                               0.6074 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c035)          0.1778 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1814 sec\n",
      "    HOTA.eval_sequence()                                                   0.1460 sec\n",
      "    Identity.eval_sequence()                                               0.0303 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "21 eval_sequence(s04_c035, metric_learning)                               0.5443 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c036)          0.1806 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1796 sec\n",
      "    HOTA.eval_sequence()                                                   0.1949 sec\n",
      "    Identity.eval_sequence()                                               0.0374 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "22 eval_sequence(s04_c036, metric_learning)                               0.6053 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c037)          0.1695 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1956 sec\n",
      "    HOTA.eval_sequence()                                                   0.1845 sec\n",
      "    Identity.eval_sequence()                                               0.0453 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "23 eval_sequence(s04_c037, metric_learning)                               0.6053 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c038)          0.1560 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.2040 sec\n",
      "    HOTA.eval_sequence()                                                   0.2037 sec\n",
      "    Identity.eval_sequence()                                               0.0413 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "24 eval_sequence(s04_c038, metric_learning)                               0.6151 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c039)          0.2128 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1935 sec\n",
      "    HOTA.eval_sequence()                                                   0.1367 sec\n",
      "    Identity.eval_sequence()                                               0.0302 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "25 eval_sequence(s04_c039, metric_learning)                               0.5793 sec\n",
      "    MotChallenge2DBox.get_raw_seq_data(metric_learning, s04_c040)          0.1793 sec\n",
      "    MotChallenge2DBox.get_preprocessed_seq_data(pedestrian)                0.1852 sec\n",
      "    HOTA.eval_sequence()                                                   0.1828 sec\n",
      "    Identity.eval_sequence()                                               0.0280 sec\n",
      "    Count.eval_sequence()                                                  0.0000 sec\n",
      "26 eval_sequence(s04_c040, metric_learning)                               0.5856 sec\n",
      "\n",
      "All sequences for metric_learning finished in 15.21 seconds\n",
      "\n",
      "HOTA: metric_learning-pedestrian   HOTA      DetA      AssA      DetRe     DetPr     AssRe     AssPr     LocA      OWTA      HOTA(0)   LocA(0)   HOTALocA(0)\n",
      "s04_c016                           19.693    15.528    26.124    37.694    19.09     28.941    64.676    70.937    30.863    30.189    58.55     17.676    \n",
      "s04_c017                           7.501     7.3689    7.959     38.955    8.0871    8.2449    69.522    73.792    17.277    10.846    59.646    6.469     \n",
      "s04_c018                           7.9667    5.6992    11.262    51.833    5.8763    15.905    47.718    72.379    24.044    12.149    60.786    7.3848    \n",
      "s04_c019                           15.05     19.838    12.971    70.927    20.389    20.042    72.54     77.96     28.586    18.93     73.259    13.868    \n",
      "s04_c020                           6.6372    3.8124    11.981    52.867    3.8733    16.179    47.657    70.276    24.749    10.61     55.651    5.9046    \n",
      "s04_c021                           10.557    7.5179    15.152    61.396    7.6957    16.467    60.511    74.619    30.217    15.152    62.31     9.4413    \n",
      "s04_c022                           6.7404    7.4337    6.6197    45.592    7.7832    7.3029    54.797    68.606    16.764    11.789    51.046    6.0181    \n",
      "s04_c023                           6.6407    3.7222    12.453    47.368    3.7959    16.026    45.164    67.863    23.72     11.391    50.822    5.7891    \n",
      "s04_c024                           7.4607    1.8118    30.841    76.731    1.819     43.446    59.545    87.285    48.555    8.4268    85.884    7.2373    \n",
      "s04_c025                           6.0078    3.7295    10.454    50.8      3.7995    17.938    32.713    70.634    22.214    9.6936    56.528    5.4795    \n",
      "s04_c026                           9.1033    7.7526    11.559    48.445    8.0578    12.849    44.549    68.291    22.852    14.571    54.171    7.8934    \n",
      "s04_c027                           5.3515    5.2282    5.7003    40.599    5.4474    6.6747    38.796    66.325    14.949    10.31     45.302    4.6708    \n",
      "s04_c028                           4.3843    1.2438    15.965    18.378    1.3066    17.349    51.185    69.123    16.86     7.3818    52.896    3.9047    \n",
      "s04_c029                           14.313    12.949    16.416    51.232    13.978    17.553    60.086    72.518    28.571    20.718    59.912    12.413    \n",
      "s04_c030                           12.075    10.571    15.345    44.134    11.252    19.269    46.387    67.064    24.815    22.249    50.552    11.247    \n",
      "s04_c031                           4.7571    1.1741    19.886    69.023    1.1779    46.958    28.434    82.35     36.48     5.6856    77.891    4.4286    \n",
      "s04_c032                           8.7067    7.4099    11.747    36.695    7.9478    16.644    44.651    66.648    19.513    17.134    43.238    7.4084    \n",
      "s04_c033                           15.506    22.071    11.874    49.25     25.281    13.525    47.438    70.958    23.308    23.812    58.967    14.041    \n",
      "s04_c034                           9.6767    12.121    8.1406    41.21     13.716    11.368    35.411    70.314    17.926    15.412    53.565    8.2555    \n",
      "s04_c035                           24.207    35.155    18.338    47.032    48.67     20.5      54.369    74.428    28.302    33.726    65.682    22.152    \n",
      "s04_c036                           13.892    18.567    10.91     38.284    23.367    14.796    36.658    69.569    20.077    23.71     51.677    12.253    \n",
      "s04_c037                           23.287    29.203    18.961    45.761    39.913    24.214    50.924    77.301    29.259    32.403    65.976    21.378    \n",
      "s04_c038                           21.311    23.941    20.01     49.177    28.231    25.877    46.938    72.325    30.773    32.126    60.796    19.532    \n",
      "s04_c039                           18.455    23.475    14.819    44.71     30.257    23.351    50.885    75.979    25.565    28.712    63.342    18.187    \n",
      "s04_c040                           18.734    11.807    30.921    44.634    12.584    40.063    49.993    66.248    36.505    37.714    49.061    18.503    \n",
      "COMBINED                           11.214    9.1154    14.967    45.843    9.7695    19.226    50.489    70.482    25.245    17.604    55.87     9.8352    \n",
      "\n",
      "Identity: metric_learning-pedestrianIDF1      IDR       IDP       IDTP      IDFN      IDFP      \n",
      "s04_c016                           17.137    25.487    12.908    170       497       1147      \n",
      "s04_c017                           5.0847    14.789    3.0702    42        242       1326      \n",
      "s04_c018                           5.8287    28.621    3.2447    83        207       2475      \n",
      "s04_c019                           12.589    28.191    8.104     106       270       1202      \n",
      "s04_c020                           3.7697    27.612    2.023     74        194       3584      \n",
      "s04_c021                           7.1148    31.938    4.0033    145       309       3477      \n",
      "s04_c022                           3.6722    12.591    2.1495    69        479       3141      \n",
      "s04_c023                           3.7095    25        2.0034    83        249       4060      \n",
      "s04_c024                           2.3157    50        1.1853    19        19        1584      \n",
      "s04_c025                           3.5371    25.414    1.9008    92        270       4748      \n",
      "s04_c026                           7.1934    25.221    4.1949    371       1100      8473      \n",
      "s04_c027                           3.1857    13.464    1.8065    96        617       5218      \n",
      "s04_c028                           2.1763    16.393    1.1655    20        102       1696      \n",
      "s04_c029                           11.455    26.721    7.2901    198       543       2518      \n",
      "s04_c030                           7.7732    19.131    4.8775    207       875       4037      \n",
      "s04_c031                           1.8599    55.422    0.94582   92        74        9635      \n",
      "s04_c032                           4.5455    12.766    2.765     96        656       3376      \n",
      "s04_c033                           15.518    22.874    11.741    476       1605      3578      \n",
      "s04_c034                           9.9057    19.834    6.6014    310       1253      4386      \n",
      "s04_c035                           26.712    26.263    27.178    156       438       418       \n",
      "s04_c036                           15.204    20.057    12.242    350       1395      2509      \n",
      "s04_c037                           28.831    30.943    26.988    302       674       817       \n",
      "s04_c038                           23.176    31.774    18.241    197       423       883       \n",
      "s04_c039                           17.753    21.993    14.884    64        227       366       \n",
      "s04_c040                           14.298    32.507    9.1645    249       517       2468      \n",
      "COMBINED                           8.2586    23.506    5.0093    4067      13235     77122     \n",
      "\n",
      "Count: metric_learning-pedestrian  Dets      GT_Dets   IDs       GT_IDs    \n",
      "s04_c016                           1317      667       240       7         \n",
      "s04_c017                           1368      284       165       6         \n",
      "s04_c018                           2558      290       181       7         \n",
      "s04_c019                           1308      376       120       8         \n",
      "s04_c020                           3658      268       279       7         \n",
      "s04_c021                           3622      454       315       6         \n",
      "s04_c022                           3210      548       321       7         \n",
      "s04_c023                           4143      332       246       9         \n",
      "s04_c024                           1603      38        180       9         \n",
      "s04_c025                           4840      362       251       11        \n",
      "s04_c026                           8844      1471      489       10        \n",
      "s04_c027                           5314      713       435       7         \n",
      "s04_c028                           1716      122       156       2         \n",
      "s04_c029                           2716      741       292       9         \n",
      "s04_c030                           4244      1082      267       22        \n",
      "s04_c031                           9727      166       343       20        \n",
      "s04_c032                           3472      752       228       22        \n",
      "s04_c033                           4054      2081      274       26        \n",
      "s04_c034                           4696      1563      237       20        \n",
      "s04_c035                           574       594       87        14        \n",
      "s04_c036                           2859      1745      154       21        \n",
      "s04_c037                           1119      976       81        16        \n",
      "s04_c038                           1080      620       72        19        \n",
      "s04_c039                           430       291       37        14        \n",
      "s04_c040                           2717      766       69        13        \n",
      "COMBINED                           81189     17302     5519      312       \n",
      "\n",
      "Timing analysis:\n",
      "MotChallenge2DBox.get_raw_seq_data                                     4.5799 sec\n",
      "MotChallenge2DBox.get_preprocessed_seq_data                            5.1145 sec\n",
      "HOTA.eval_sequence                                                     4.3115 sec\n",
      "Identity.eval_sequence                                                 0.9268 sec\n",
      "Count.eval_sequence                                                    0.0001 sec\n",
      "eval_sequence                                                          15.2027 sec\n",
      "Evaluator.evaluate                                                     16.0204 sec\n"
     ]
    }
   ],
   "source": [
    "!python TrackEval/scripts/run_mot_challenge.py --BENCHMARK parabellum-s04 --SPLIT_TO_EVAL train --TRACKERS_TO_EVAL metric_learning --METRICS HOTA Identity --DO_PREPROC False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
