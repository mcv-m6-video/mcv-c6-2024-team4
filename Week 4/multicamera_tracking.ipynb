{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "from sort import Sort\n",
    "import pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition remains the same\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', weights='ResNet50_Weights.DEFAULT')\n",
    "        self.model.fc = nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "model = Net()\n",
    "yolo = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths = ['aic19-track1-mtmc-train/train/S01/c001/vdo.avi', \n",
    "               'aic19-track1-mtmc-train/train/S01/c002/vdo.avi', \n",
    "               'aic19-track1-mtmc-train/train/S01/c003/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S01/c004/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S01/c005/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c010/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c011/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c012/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c013/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c014/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S03/c015/vdo10.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c016/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c017/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c018/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c019/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c020/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c021/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c022/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c023/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c024/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c025/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c026/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c027/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c028/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c029/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c030/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c031/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c032/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c033/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c034/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c035/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c036/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c037/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c038/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c039/vdo.avi',\n",
    "               'aic19-track1-mtmc-train/train/S04/c040/vdo.avi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale_fps(input_path, output_path, input_fps=8, target_fps=10):\n",
    "    \"\"\"\n",
    "    This function upscales the FPS of a video by interpolating frames using OpenCV and NumPy.\n",
    "    \n",
    "    Parameters:\n",
    "    input_path (str): The path to the input video file.\n",
    "    output_path (str): The path where the output video will be saved.\n",
    "    input_fps (int): The original FPS of the video.\n",
    "    target_fps (int): The target FPS to upscale the video to.\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    \n",
    "    # Capture video from input path\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    if not cap.isOpened():\n",
    "        return \"Failed to open video file.\"\n",
    "    \n",
    "    # Get video properties\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, target_fps, (width, height))\n",
    "    \n",
    "    prev_frame = None\n",
    "    success, frame = cap.read()\n",
    "    while success:\n",
    "        out.write(frame)  # Write the original frame\n",
    "        \n",
    "        # If there's a previous frame, generate interpolated frames\n",
    "        if prev_frame is not None:\n",
    "            # Generate interpolated frames\n",
    "            for _ in range((target_fps // input_fps) - 1):\n",
    "                interp_frame = cv2.addWeighted(prev_frame, 0.5, frame, 0.5, 0)\n",
    "                out.write(interp_frame)\n",
    "                \n",
    "        prev_frame = frame\n",
    "        success, frame = cap.read()\n",
    "        \n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    return \"Video FPS upscaled successfully.\"\n",
    "\n",
    "# upscale_fps('aic19-track1-mtmc-train/train/S03/c015/vdo.avi', 'aic19-track1-mtmc-train/train/S03/c015/vdo10.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_detections(video_path, yolo):\n",
    "    \"\"\"\n",
    "    Given a video, create detections for each frame in the video and store bounding boxes in a text file\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Create a text file to store the bounding boxes\n",
    "    f = open(f\"detections/{video_path.split('/')[-2].split('.')[0]}.txt\", \"w\")\n",
    "\n",
    "    frame_num = 0\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Get the detections for the frame\n",
    "        detections = yolo(frame, verbose=False)\n",
    "\n",
    "        # Write the bounding boxes to the text file\n",
    "        for box in detections[0].boxes:\n",
    "            if box.cls == 2:\n",
    "                x1, y1, x2, y2 = box.xyxy[0].int().tolist()\n",
    "                f.write(f\"{frame_num},{x1},{y1},{x2},{y2}\\n\")\n",
    "\n",
    "        frame_num += 1\n",
    "\n",
    "    f.close()\n",
    "    cap.release()\n",
    "\n",
    "# for video in tqdm(video_paths):\n",
    "#     create_detections(video, yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "\n",
    "# Initialization\n",
    "camera_trackers = {camera_id: Sort() for camera_id in camera_ids}  # SORT tracker for each camera\n",
    "global_tracks = []\n",
    "\n",
    "def update_global_tracks(tracked_detections, camera_id):\n",
    "    \"\"\"\n",
    "    Update global tracks with new detections from a specific camera.\n",
    "    This function attempts to match new detections to existing global tracks\n",
    "    and creates new global tracks for unmatched detections.\n",
    "    \"\"\"\n",
    "    # Placeholder for matching logic between tracked_detections and global_tracks\n",
    "    # This function should use the siamese_nn to compute similarities\n",
    "    # and match detections across cameras, updating global_tracks accordingly.\n",
    "\n",
    "def track_across_cameras(detections):\n",
    "    \"\"\"\n",
    "    Main function to handle tracking across multiple cameras.\n",
    "    \"\"\"\n",
    "    # Step 1: Update tracks within each camera using SORT\n",
    "    local_tracks = {}\n",
    "    for camera_id, dets in detections.items():\n",
    "        tracked_detections = camera_trackers[camera_id].update(np.array(dets))\n",
    "        local_tracks[camera_id] = tracked_detections\n",
    "\n",
    "    # Step 2: Update global tracks with detections from all cameras\n",
    "    for camera_id, tracked_detections in local_tracks.items():\n",
    "        update_global_tracks(tracked_detections, camera_id)\n",
    "\n",
    "    # Step 3 (Optional): Handle cross-camera tracking logic\n",
    "    # This could involve additional steps to refine track matching across cameras,\n",
    "    # especially if tracks move from the view of one camera to another.\n",
    "\n",
    "track_across_cameras(detections)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
