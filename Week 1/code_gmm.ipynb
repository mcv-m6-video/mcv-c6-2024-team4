{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame count: 2141 FPS: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66/66 [00:02<00:00, 23.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from data_utils import extract_rectangles_from_xml\n",
    "from evaluation import mAP\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import skimage.transform\n",
    "\n",
    "annotation = extract_rectangles_from_xml('data/ai_challenge_s03_c010-full_annotation.xml')\n",
    "parked_cars = annotation[0]\n",
    "\n",
    "cap = cv2.VideoCapture('data/S03/c010/vdo.avi')\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print('Frame count:', frame_count, 'FPS:', fps)\n",
    "\n",
    "split_frame = frame_count // 32\n",
    "\n",
    "frames = []\n",
    "for i in tqdm.tqdm(range(split_frame)):  # Process 25% of the frames\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frames.append(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float64))\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gmm_to_pixels(frames, k=3):\n",
    "    # Assuming frames are downsampled and in grayscale\n",
    "    height, width = frames[0].shape\n",
    "    \n",
    "    # Prepare data for GMM: reshape frames to have all pixel values across all frames in a list\n",
    "    pixel_values = np.stack([f.flatten() for f in tqdm.tqdm(frames, desc='Stacking...')], axis=1)\n",
    "    \n",
    "    # Initialize storage for GMM parameters\n",
    "    means = np.zeros((height, width, k))\n",
    "    variances = np.zeros((height, width, k))\n",
    "    weights = np.zeros((height, width, k))\n",
    "    \n",
    "    # Fit GMM for each pixel\n",
    "    for i in tqdm.tqdm(range(height), desc='Fitting GMM'):\n",
    "        for j in range(width):\n",
    "            gmm = GaussianMixture(n_components=k, covariance_type='spherical', max_iter=25, tol=1e-1, random_state=123, n_init=1, init_params='k-means++')\n",
    "            pixel_series = pixel_values[i * width + j].reshape(-1, 1)\n",
    "            gmm.fit(pixel_series)\n",
    "            \n",
    "            # Store the means and variances of the fitted Gaussians\n",
    "            means[i, j, :] = gmm.means_.flatten()\n",
    "            variances[i, j, :] = gmm.covariances_\n",
    "            weights[i, j, :] = gmm.weights_\n",
    "    \n",
    "    return means, variances, weights\n",
    "\n",
    "def downsample_frames(frames, scale=0.5):\n",
    "    return [skimage.transform.rescale(frame, scale, anti_aliasing=True) for frame in tqdm.tqdm(frames, desc='Downsampling frames')]\n",
    "\n",
    "def upsample_image(image, target_height, target_width):\n",
    "    return skimage.transform.resize(image, (target_height, target_width), anti_aliasing=True)\n",
    "\n",
    "# downsampled_frames = downsample_frames(frames, scale=0.5)\n",
    "\n",
    "# Compute GMM parameters\n",
    "# means, variances, weights = fit_gmm_to_pixels(downsampled_frames)\n",
    "\n",
    "# Upsample results back to original resolution\n",
    "original_height, original_width = frames[0].shape\n",
    "upsampled_means = upsample_image(means, original_height, original_width)\n",
    "upsampled_variances = upsample_image(variances, original_height, original_width)\n",
    "upsampled_weights = upsample_image(weights, original_height, original_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open('gmm_params.pkl', 'wb') as f:\n",
    "    pkl.dump((upsampled_means, upsampled_variances, upsampled_weights), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_shadow_gabor(image):\n",
    "    # Gabor filter parameters\n",
    "    num = 8  # Number of different orientations\n",
    "    vects = 8  # Number of different wavelengths (vector sizes)\n",
    "\n",
    "    gabor_features = np.zeros((image.shape[0], image.shape[1], num * vects), dtype=np.double)\n",
    "\n",
    "    for i in range(num):\n",
    "        theta = i / num * np.pi\n",
    "        for j in range(vects):\n",
    "            lamda = int(image.shape[0] / (2 ** j))\n",
    "            g_kernel = cv2.getGaborKernel((lamda, lamda), sigma=4.0, theta=theta, lambd=lamda, gamma=0.5)\n",
    "            filtered_img = cv2.filter2D(image, cv2.CV_8UC3, g_kernel)\n",
    "            gabor_features[:, :, i * vects + j] = filtered_img\n",
    "\n",
    "    gabor_features_binary = (gabor_features.mean(axis=2) > 2.5*gabor_features.mean(axis=2).mean()).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    # Find the columns that have non-zero values\n",
    "    non_zero_columns = np.where(gabor_features_binary.sum(axis=0) > 0)[0]\n",
    "\n",
    "    if len(non_zero_columns) == 0:\n",
    "        return 0, image.shape[1]\n",
    "    # The minimum and maximum x values with non-zero values (bbox horizontal)\n",
    "    min_x = non_zero_columns.min()\n",
    "    max_x = non_zero_columns.max()\n",
    "\n",
    "    return min_x, max_x\n",
    "\n",
    "# Function to calculate if rectangles a and b are close\n",
    "def are_close(a, b, proximity_threshold):\n",
    "    left_a, top_a, right_a, bottom_a = a\n",
    "    left_b, top_b, right_b, bottom_b = b\n",
    "\n",
    "    # Check if rectangles are close based on the threshold\n",
    "    horizontal_close = (left_b <= right_a + proximity_threshold and right_b >= left_a - proximity_threshold)\n",
    "    vertical_close = (top_b <= bottom_a + proximity_threshold and bottom_b >= top_a - proximity_threshold)\n",
    "\n",
    "    return horizontal_close and vertical_close\n",
    "\n",
    "# Function to merge two rectangles\n",
    "def merge_rects(a, b):\n",
    "    left_a, top_a, right_a, bottom_a = a\n",
    "    left_b, top_b, right_b, bottom_b = b\n",
    "    return (min(left_a, left_b), min(top_a, top_b), max(right_a, right_b), max(bottom_a, bottom_b))\n",
    "\n",
    "def merge_close_rectangles(rectangles, proximity_threshold):\n",
    "    # Convert rectangles to a format that includes the bottom-right corner for easier comparison\n",
    "    rects_with_br = [(x, y, x+w, y+h) for x, y, w, h in rectangles]\n",
    "\n",
    "    merged = True\n",
    "    while merged:\n",
    "        merged = False\n",
    "        new_rects = []\n",
    "        while rects_with_br:\n",
    "            current = rects_with_br.pop(0)\n",
    "            for i, other in enumerate(rects_with_br):\n",
    "                if are_close(current, other, proximity_threshold):\n",
    "                    new_rect = merge_rects(current, other)\n",
    "                    rects_with_br[i] = new_rect  # Replace the \"other\" rect with the merged one\n",
    "                    current = new_rect  # Update current to be the merged rect\n",
    "                    merged = True\n",
    "                    break\n",
    "            else:\n",
    "                new_rects.append(current)  # Add current rect if it wasn't merged\n",
    "        rects_with_br = new_rects  # Update list with merged rects\n",
    "\n",
    "    # Convert back to original format\n",
    "    merged_rectangles = [(left, top, right-left, bottom-top) for left, top, right, bottom in rects_with_br]\n",
    "    return merged_rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_bbox = [\n",
    "    [list(np.array(r).astype(int)) for r in rect if r not in parked_cars]\n",
    "    for rect in list(annotation.values())[split_frame:]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(color_frame, mean, variance, weights, alpha, alpha2, ro):\n",
    "    \"\"\"\n",
    "    Process a single frame for background/foreground separation using a Gaussian Mixture Model.\n",
    "\n",
    "    Parameters:\n",
    "    - frame: The current frame as a 2D array.\n",
    "    - alpha: Learning rate for weight update.\n",
    "    - ro: Learning rate for mean and variance update.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple of (background, foreground) images.\n",
    "    \"\"\"\n",
    "\n",
    "    def sort_gaussians(pixel_data):\n",
    "        return sorted(pixel_data, key=lambda x: x[0] / x[3], reverse=True)\n",
    "    \n",
    "    k = 3  # Number of Gaussians\n",
    "    T = 0.7  # Threshold for background/foreground separation\n",
    "    gray_frame = cv2.cvtColor(color_frame, cv2.COLOR_BGR2GRAY)\n",
    "    num_pixels = gray_frame.size\n",
    "\n",
    "    frame = gray_frame.flatten()\n",
    "    foreground = np.zeros_like(frame)\n",
    "\n",
    "    for i in range(num_pixels):\n",
    "        matched = False\n",
    "        for ki in range(k):\n",
    "            if abs(frame[i] - mean[i, ki]) < alpha * np.sqrt(variance[i, ki]):\n",
    "                # Update matched Gaussian parameters\n",
    "                mean[i, ki] = (1 - ro) * mean[i, ki] + ro * frame[i]\n",
    "                variance[i, ki] = (1 - ro) * variance[i, ki] + ro * (frame[i] - mean[i, ki]) ** 2\n",
    "                weights[i, ki] = (1 - alpha2) * weights[i, ki] + alpha2\n",
    "                matched = True\n",
    "            else:\n",
    "                weights[i, ki] *= (1 - alpha2)\n",
    "\n",
    "        if not matched:\n",
    "            # Replace least likely Gaussian with current pixel value\n",
    "            idx = np.argmin(weights[i])\n",
    "            mean[i, idx] = frame[i]\n",
    "            variance[i, idx] = 9999  # Reset to a high variance\n",
    "\n",
    "        # Normalize weights\n",
    "        weights[i] /= weights[i].sum()\n",
    "\n",
    "        # Sort Gaussians by weight/variance ratio\n",
    "        combined = sort_gaussians(list(zip(weights[i], mean[i], variance[i])))\n",
    "        weights[i], mean[i], variance[i] = map(np.array, zip(*combined))\n",
    "\n",
    "        # Determine background/foreground\n",
    "        sum_weights = 0\n",
    "        for ki in range(k):\n",
    "            sum_weights += weights[i, ki]\n",
    "            if sum_weights > T:\n",
    "                if matched and abs(frame[i] - mean[i, ki]) <= alpha * np.sqrt(variance[i, ki]):\n",
    "                    foreground[i] = 255  # Mark as background\n",
    "                else:\n",
    "                    foreground[i] = frame[i]  # Mark as foreground\n",
    "                break\n",
    "    \n",
    "    foreground_binary = foreground.reshape(frame.shape)\n",
    "    foreground_clean = cv2.morphologyEx(foreground_binary, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "    foreground_clean = cv2.morphologyEx(foreground_clean, cv2.MORPH_OPEN, np.ones((7,7), np.uint8))\n",
    "\n",
    "    contours, _ = cv2.findContours(foreground_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rectangles_merged = merge_close_rectangles([cv2.boundingRect(contour) for contour in contours], 20)\n",
    "    \n",
    "    rectangles_output = []\n",
    "    for i, (x, y, w, h) in enumerate(rectangles_merged):\n",
    "\n",
    "        if w < 80 or h < 80:\n",
    "            continue\n",
    "\n",
    "        new_xmin = remove_shadow_gabor(gray_frame[y:y+h, x:x+w])[0]\n",
    "        rectangles_output.append([x + new_xmin, y, x + w, y + h])\n",
    "\n",
    "        foreground_clean[y:y+h, x:x+new_xmin] = 0\n",
    "\n",
    "    return rectangles_output, foreground_binary, foreground_clean, mean, variance\n",
    "\n",
    "def process_video(video_path, split_frame, frame_count, mean, variance, gt_bbox, alpha, alpha2, rho):\n",
    "    \"\"\"Process the video to overlay predicted and ground truth bounding boxes.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    mAPs = []\n",
    "    \n",
    "    for n in tqdm.tqdm(range(split_frame, frame_count, 100)):\n",
    "        print(f'Processing frames {n-split_frame} to {min(n+100, frame_count)-split_frame}...')\n",
    "        out = cv2.VideoWriter(f'media/output_{n-split_frame}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height))\n",
    "        out2 = cv2.VideoWriter(f'media/output_{n-split_frame}_binary.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height), isColor=False)\n",
    "        out3 = cv2.VideoWriter(f'media/output_{n-split_frame}_clean.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height), isColor=False)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, n)\n",
    "        pred_bbox = []\n",
    "\n",
    "        for _ in range(n, min(n+100, frame_count)):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            bbox, binary, clean, mean, variance = process_frame(frame, mean, variance, alpha, alpha2, rho)\n",
    "            \n",
    "            pred_bbox.append(bbox)\n",
    "            out2.write(binary)\n",
    "            out3.write(clean)\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, n)\n",
    "        for i, _ in enumerate(pred_bbox):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            for rect in pred_bbox[i]:\n",
    "                cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (0, 0, 255), 2)\n",
    "            # Assuming gt_bbox is defined elsewhere and accessible here\n",
    "            for rect in gt_bbox[n + i - split_frame]:\n",
    "                cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
    "\n",
    "            out.write(frame)\n",
    "        m = mAP(gt_bbox[(n - split_frame):(min(n+100, frame_count)- split_frame)], pred_bbox)\n",
    "        mAPs.append(m)\n",
    "        \n",
    "        out.release()\n",
    "        out2.release()\n",
    "        out3.release()\n",
    "\n",
    "    print('mAP:', np.mean(mAPs))\n",
    "    cap.release()\n",
    "    return mAPs\n",
    "\n",
    "process_video('data/S03/c010/vdo.avi', split_frame, frame_count, means, variances, gt_bbox, 2, 0.01, 0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
