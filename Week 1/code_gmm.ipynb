{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import extract_rectangles_from_xml\n",
    "from evaluation import mAP\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "annotation = extract_rectangles_from_xml('data/ai_challenge_s03_c010-full_annotation.xml')\n",
    "parked_cars = annotation[0]\n",
    "\n",
    "cap = cv2.VideoCapture('data/S03/c010/vdo.avi')\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print('Frame count:', frame_count, 'FPS:', fps)\n",
    "\n",
    "split_frame = frame_count // 4\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_shadow_gabor(image):\n",
    "    # Gabor filter parameters\n",
    "    num = 8  # Number of different orientations\n",
    "    vects = 8  # Number of different wavelengths (vector sizes)\n",
    "\n",
    "    gabor_features = np.zeros((image.shape[0], image.shape[1], num * vects), dtype=np.double)\n",
    "\n",
    "    for i in range(num):\n",
    "        theta = i / num * np.pi\n",
    "        for j in range(vects):\n",
    "            lamda = int(image.shape[0] / (2 ** j))\n",
    "            g_kernel = cv2.getGaborKernel((lamda, lamda), sigma=4.0, theta=theta, lambd=lamda, gamma=0.5)\n",
    "            filtered_img = cv2.filter2D(image, cv2.CV_8UC3, g_kernel)\n",
    "            gabor_features[:, :, i * vects + j] = filtered_img\n",
    "\n",
    "    gabor_features_binary = (gabor_features.mean(axis=2) > 2.5*gabor_features.mean(axis=2).mean()).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    # Find the columns that have non-zero values\n",
    "    non_zero_columns = np.where(gabor_features_binary.sum(axis=0) > 0)[0]\n",
    "\n",
    "    if len(non_zero_columns) == 0:\n",
    "        return 0, image.shape[1]\n",
    "    # The minimum and maximum x values with non-zero values (bbox horizontal)\n",
    "    min_x = non_zero_columns.min()\n",
    "    max_x = non_zero_columns.max()\n",
    "\n",
    "    return min_x, max_x\n",
    "\n",
    "# Function to calculate if rectangles a and b are close\n",
    "def are_close(a, b, proximity_threshold):\n",
    "    left_a, top_a, right_a, bottom_a = a\n",
    "    left_b, top_b, right_b, bottom_b = b\n",
    "\n",
    "    # Check if rectangles are close based on the threshold\n",
    "    horizontal_close = (left_b <= right_a + proximity_threshold and right_b >= left_a - proximity_threshold)\n",
    "    vertical_close = (top_b <= bottom_a + proximity_threshold and bottom_b >= top_a - proximity_threshold)\n",
    "\n",
    "    return horizontal_close and vertical_close\n",
    "\n",
    "# Function to merge two rectangles\n",
    "def merge_rects(a, b):\n",
    "    left_a, top_a, right_a, bottom_a = a\n",
    "    left_b, top_b, right_b, bottom_b = b\n",
    "    return (min(left_a, left_b), min(top_a, top_b), max(right_a, right_b), max(bottom_a, bottom_b))\n",
    "\n",
    "def merge_close_rectangles(rectangles, proximity_threshold):\n",
    "    # Convert rectangles to a format that includes the bottom-right corner for easier comparison\n",
    "    rects_with_br = [(x, y, x+w, y+h) for x, y, w, h in rectangles]\n",
    "\n",
    "    merged = True\n",
    "    while merged:\n",
    "        merged = False\n",
    "        new_rects = []\n",
    "        while rects_with_br:\n",
    "            current = rects_with_br.pop(0)\n",
    "            for i, other in enumerate(rects_with_br):\n",
    "                if are_close(current, other, proximity_threshold):\n",
    "                    new_rect = merge_rects(current, other)\n",
    "                    rects_with_br[i] = new_rect  # Replace the \"other\" rect with the merged one\n",
    "                    current = new_rect  # Update current to be the merged rect\n",
    "                    merged = True\n",
    "                    break\n",
    "            else:\n",
    "                new_rects.append(current)  # Add current rect if it wasn't merged\n",
    "        rects_with_br = new_rects  # Update list with merged rects\n",
    "\n",
    "    # Convert back to original format\n",
    "    merged_rectangles = [(left, top, right-left, bottom-top) for left, top, right, bottom in rects_with_br]\n",
    "    return merged_rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_bbox = [\n",
    "    [list(np.array(r).astype(int)) for r in rect if r not in parked_cars]\n",
    "    for rect in list(annotation.values())[split_frame:]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame, mean, variance, weights, alpha, ro):\n",
    "    \"\"\"\n",
    "    Process a single frame for background/foreground separation using a Gaussian Mixture Model.\n",
    "\n",
    "    Parameters:\n",
    "    - frame: The current frame as a 2D array.\n",
    "    - alpha: Learning rate for weight update.\n",
    "    - ro: Learning rate for mean and variance update.\n",
    "\n",
    "    Returns:\n",
    "    - A tuple of (background, foreground) images.\n",
    "    \"\"\"\n",
    "\n",
    "    def sort_gaussians(pixel_data):\n",
    "        return sorted(pixel_data, key=lambda x: x[0] / x[3], reverse=True)\n",
    "    \n",
    "    k = 3  # Number of Gaussians\n",
    "    T = 0.7  # Threshold for background/foreground separation\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    num_pixels = frame.size\n",
    "\n",
    "    frame = frame.flatten()\n",
    "    foreground = np.zeros_like(frame)\n",
    "\n",
    "    for i in range(num_pixels):\n",
    "        matched = False\n",
    "        for ki in range(k):\n",
    "            if abs(frame[i] - mean[i][ki]) < 2.5 * np.sqrt(variance[i][ki]):\n",
    "                # Update matched Gaussian parameters\n",
    "                mean[i][ki] = (1 - ro) * mean[i][ki] + ro * frame[i]\n",
    "                variance[i][ki] = (1 - ro) * variance[i][ki] + ro * (frame[i] - mean[i][ki]) ** 2\n",
    "                weights[i][ki] = (1 - alpha) * weights[i][ki] + alpha\n",
    "                matched = True\n",
    "            else:\n",
    "                weights[i][ki] *= (1 - alpha)\n",
    "\n",
    "        if not matched:\n",
    "            # Replace least likely Gaussian with current pixel value\n",
    "            idx = np.argmin(weights[i])\n",
    "            mean[i][idx] = frame[i]\n",
    "            variance[i][idx] = 9999  # Reset to a high variance\n",
    "\n",
    "        # Normalize weights\n",
    "        weights[i] /= weights[i].sum()\n",
    "\n",
    "        # Sort Gaussians by weight/variance ratio\n",
    "        combined = sort_gaussians(list(zip(weights[i], mean[i], variance[i])))\n",
    "        weights[i], mean[i], variance[i] = map(np.array, zip(*combined))\n",
    "\n",
    "        # Determine background/foreground\n",
    "        sum_weights = 0\n",
    "        for ki in range(k):\n",
    "            sum_weights += weights[i][ki]\n",
    "            if sum_weights > T:\n",
    "                if matched and abs(frame[i] - mean[i][ki]) <= 2.5 * np.sqrt(variance[i][ki]):\n",
    "                    foreground[i] = 255  # Mark as background\n",
    "                else:\n",
    "                    foreground[i] = frame[i]  # Mark as foreground\n",
    "                break\n",
    "    \n",
    "    foreground = foreground.reshape(frame.shape)\n",
    "    foreground_clean = cv2.morphologyEx(foreground, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "    foreground_clean = cv2.morphologyEx(foreground_clean, cv2.MORPH_OPEN, np.ones((7,7), np.uint8))\n",
    "\n",
    "    contours, _ = cv2.findContours(foreground_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rectangles_merged = merge_close_rectangles([cv2.boundingRect(contour) for contour in contours], 20)\n",
    "    \n",
    "    rectangles_output = []\n",
    "    for i, (x, y, w, h) in enumerate(rectangles_merged):\n",
    "\n",
    "        if w < 80 or h < 80:\n",
    "            continue\n",
    "\n",
    "        new_xmin = remove_shadow_gabor(gray_frame[y:y+h, x:x+w])[0]\n",
    "        rectangles_output.append([x + new_xmin, y, x + w, y + h])\n",
    "\n",
    "        foreground_clean[y:y+h, x:x+new_xmin] = 0\n",
    "\n",
    "    return rectangles_output, foreground_binary, foreground_clean, mean, variance\n",
    "\n",
    "def process_video(video_path, split_frame, frame_count, mean, variance, gt_bbox, alpha, rho):\n",
    "    \"\"\"Process the video to overlay predicted and ground truth bounding boxes.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    mAPs = []\n",
    "    \n",
    "    for n in range(split_frame, frame_count, 100):\n",
    "        print(f'Processing frames {n-split_frame} to {min(n+100, frame_count)-split_frame}...')\n",
    "        out = cv2.VideoWriter(f'media/output_{n-split_frame}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height))\n",
    "        out2 = cv2.VideoWriter(f'media/output_{n-split_frame}_binary.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height), isColor=False)\n",
    "        out3 = cv2.VideoWriter(f'media/output_{n-split_frame}_clean.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height), isColor=False)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, n)\n",
    "        pred_bbox = []\n",
    "\n",
    "        for j in tqdm.tqdm(range(n, min(n+100, frame_count))):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            bbox, binary, clean, mean, variance = process_frame(frame, mean, variance, alpha, rho)\n",
    "            \n",
    "            pred_bbox.append(bbox)\n",
    "            out2.write(binary)\n",
    "            out3.write(clean)\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, n)\n",
    "        for i, _ in enumerate(pred_bbox):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            for rect in pred_bbox[i]:\n",
    "                cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (0, 0, 255), 2)\n",
    "            # Assuming gt_bbox is defined elsewhere and accessible here\n",
    "            for rect in gt_bbox[n + i - split_frame]:\n",
    "                cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
    "\n",
    "            out.write(frame)\n",
    "        m = mAP(gt_bbox[(n - split_frame):(min(n+100, frame_count)- split_frame)], pred_bbox)\n",
    "        mAPs.append(m)\n",
    "        \n",
    "        out.release()\n",
    "        out2.release()\n",
    "        out3.release()\n",
    "\n",
    "    print('mAP:', np.mean(mAPs))\n",
    "    cap.release()\n",
    "    return mAPs"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
