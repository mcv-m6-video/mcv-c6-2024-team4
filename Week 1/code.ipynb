{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import extract_rectangles_from_xml\n",
    "from evaluation import mAP\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation = extract_rectangles_from_xml('data/ai_challenge_s03_c010-full_annotation.xml')\n",
    "parked_cars = annotation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame count: 2141 FPS: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 535/535 [01:07<00:00,  7.88it/s]\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('data/S03/c010/vdo.avi')\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "print('Frame count:', frame_count, 'FPS:', fps)\n",
    "\n",
    "split_frame = frame_count // 4\n",
    "\n",
    "# Initialize cumulative sum and sum of squares\n",
    "cum_sum = np.zeros((height, width), dtype=np.float64)\n",
    "cum_sum_sq = np.zeros((height, width), dtype=np.float64)\n",
    "\n",
    "for i in tqdm.tqdm(range(split_frame)):  # Process 25% of the frames\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY).astype(np.float64)\n",
    "    cum_sum += gray_frame\n",
    "    cum_sum_sq += gray_frame ** 2\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Calculate mean and variance\n",
    "mean = cum_sum / split_frame\n",
    "variance = (cum_sum_sq / split_frame) - (mean ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_shadow_gabor(image):\n",
    "    # Gabor filter parameters\n",
    "    num = 8  # Number of different orientations\n",
    "    vects = 8  # Number of different wavelengths (vector sizes)\n",
    "\n",
    "    gabor_features = np.zeros((image.shape[0], image.shape[1], num * vects), dtype=np.double)\n",
    "\n",
    "    for i in range(num):\n",
    "        theta = i / num * np.pi\n",
    "        for j in range(vects):\n",
    "            lamda = int(image.shape[0] / (2 ** j))\n",
    "            g_kernel = cv2.getGaborKernel((lamda, lamda), sigma=4.0, theta=theta, lambd=lamda, gamma=0.5)\n",
    "            filtered_img = cv2.filter2D(image, cv2.CV_8UC3, g_kernel)\n",
    "            gabor_features[:, :, i * vects + j] = filtered_img\n",
    "\n",
    "    gabor_features_binary = (gabor_features.mean(axis=2) > 2.5*gabor_features.mean(axis=2).mean()).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    # Find the columns that have non-zero values\n",
    "    non_zero_columns = np.where(gabor_features_binary.sum(axis=0) > 0)[0]\n",
    "\n",
    "    if len(non_zero_columns) == 0:\n",
    "        return 0, image.shape[1]\n",
    "    # The minimum and maximum x values with non-zero values (bbox horizontal)\n",
    "    min_x = non_zero_columns.min()\n",
    "    max_x = non_zero_columns.max()\n",
    "\n",
    "    return min_x, max_x\n",
    "\n",
    "# Function to calculate if rectangles a and b are close\n",
    "def are_close(a, b, proximity_threshold):\n",
    "    left_a, top_a, right_a, bottom_a = a\n",
    "    left_b, top_b, right_b, bottom_b = b\n",
    "\n",
    "    # Check if rectangles are close based on the threshold\n",
    "    horizontal_close = (left_b <= right_a + proximity_threshold and right_b >= left_a - proximity_threshold)\n",
    "    vertical_close = (top_b <= bottom_a + proximity_threshold and bottom_b >= top_a - proximity_threshold)\n",
    "\n",
    "    return horizontal_close and vertical_close\n",
    "\n",
    "# Function to merge two rectangles\n",
    "def merge_rects(a, b):\n",
    "    left_a, top_a, right_a, bottom_a = a\n",
    "    left_b, top_b, right_b, bottom_b = b\n",
    "    return (min(left_a, left_b), min(top_a, top_b), max(right_a, right_b), max(bottom_a, bottom_b))\n",
    "\n",
    "def merge_close_rectangles(rectangles, proximity_threshold):\n",
    "    # Convert rectangles to a format that includes the bottom-right corner for easier comparison\n",
    "    rects_with_br = [(x, y, x+w, y+h) for x, y, w, h in rectangles]\n",
    "\n",
    "    merged = True\n",
    "    while merged:\n",
    "        merged = False\n",
    "        new_rects = []\n",
    "        while rects_with_br:\n",
    "            current = rects_with_br.pop(0)\n",
    "            for i, other in enumerate(rects_with_br):\n",
    "                if are_close(current, other, proximity_threshold):\n",
    "                    new_rect = merge_rects(current, other)\n",
    "                    rects_with_br[i] = new_rect  # Replace the \"other\" rect with the merged one\n",
    "                    current = new_rect  # Update current to be the merged rect\n",
    "                    merged = True\n",
    "                    break\n",
    "            else:\n",
    "                new_rects.append(current)  # Add current rect if it wasn't merged\n",
    "        rects_with_br = new_rects  # Update list with merged rects\n",
    "\n",
    "    # Convert back to original format\n",
    "    merged_rectangles = [(left, top, right-left, bottom-top) for left, top, right, bottom in rects_with_br]\n",
    "    return merged_rectangles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_bbox = [\n",
    "    [list(np.array(r).astype(int)) for r in rect if r not in parked_cars]\n",
    "    for rect in list(annotation.values())[split_frame:]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame_adaptative(frame, mean, variance, alpha, rho):\n",
    "    \"\"\"Process a single frame to extract foreground bounding boxes.\"\"\"\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    abs_diff = np.abs(gray_frame - mean)\n",
    "\n",
    "    intensity = abs_diff.sum()\n",
    "    if intensity <= 25000000:\n",
    "        alpha *= 0.5\n",
    "    elif intensity >= 55000000:\n",
    "        alpha *= 1.5\n",
    "\n",
    "    foreground_mask = abs_diff >= alpha * (np.sqrt(variance) + 2)\n",
    "    foreground_binary = np.where(foreground_mask, 255, 0).astype(np.uint8)\n",
    "\n",
    "    background_mask = ~foreground_mask  # Inverting the foreground mask to get the background\n",
    "    mean[background_mask] = rho * gray_frame[background_mask] + (1 - rho) * mean[background_mask]\n",
    "    variance[background_mask] = rho * ((gray_frame[background_mask] - mean[background_mask]) ** 2) + (1 - rho) * variance[background_mask]\n",
    "    \n",
    "    foreground_clean = cv2.morphologyEx(foreground_binary, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "    foreground_clean = cv2.morphologyEx(foreground_clean, cv2.MORPH_OPEN, np.ones((7,7), np.uint8))\n",
    "\n",
    "    contours, _ = cv2.findContours(foreground_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rectangles_merged = merge_close_rectangles([cv2.boundingRect(contour) for contour in contours], 20)\n",
    "    \n",
    "    rectangles_output = []\n",
    "    for i, (x, y, w, h) in enumerate(rectangles_merged):\n",
    "\n",
    "        if w < 80 or h < 80:\n",
    "            continue\n",
    "\n",
    "        new_xmin = remove_shadow_gabor(gray_frame[y:y+h, x:x+w])[0]\n",
    "        rectangles_output.append([x + new_xmin, y, x + w, y + h])\n",
    "\n",
    "        foreground_clean[y:y+h, x:x+new_xmin] = 0\n",
    "\n",
    "    return rectangles_output, foreground_binary, foreground_clean, mean, variance\n",
    "\n",
    "def process_frame(frame, mean, variance, alpha):\n",
    "    \"\"\"Process a single frame to extract foreground bounding boxes.\"\"\"\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    abs_diff = np.abs(gray_frame - mean)\n",
    "    \n",
    "    intensity = abs_diff.sum()\n",
    "    if intensity <= 25000000:\n",
    "        alpha *= 0.5\n",
    "    elif intensity >= 55000000:\n",
    "        alpha *= 1.5\n",
    "\n",
    "    foreground_mask = abs_diff >= alpha * (np.sqrt(variance) + 2)\n",
    "    foreground_binary = np.where(foreground_mask, 255, 0).astype(np.uint8)\n",
    "    \n",
    "    foreground_clean = cv2.morphologyEx(foreground_binary, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "    foreground_clean = cv2.morphologyEx(foreground_clean, cv2.MORPH_OPEN, np.ones((7,7), np.uint8))\n",
    "\n",
    "    contours, _ = cv2.findContours(foreground_clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    rectangles_merged = merge_close_rectangles([cv2.boundingRect(contour) for contour in contours], 20)\n",
    "    \n",
    "    rectangles_output = []\n",
    "    for i, (x, y, w, h) in enumerate(rectangles_merged):\n",
    "\n",
    "        if w < 80 or h < 80:\n",
    "            continue\n",
    "\n",
    "        new_xmin = remove_shadow_gabor(gray_frame[y:y+h, x:x+w])[0]\n",
    "        rectangles_output.append([x + new_xmin, y, x + w, y + h])\n",
    "\n",
    "        foreground_clean[y:y+h, x:x+new_xmin] = 0\n",
    "\n",
    "    return rectangles_output, foreground_binary, foreground_clean\n",
    "\n",
    "def process_video(video_path, split_frame, frame_count, mean, variance, gt_bbox, alpha, rho=None, adaptative=False):\n",
    "    \"\"\"Process the video to overlay predicted and ground truth bounding boxes.\"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    mAPs = []\n",
    "    \n",
    "    for n in tqdm.tqdm(range(split_frame, frame_count, 100)):\n",
    "        print(f'Processing frames {n-split_frame} to {min(n+100, frame_count)-split_frame}...')\n",
    "        out = cv2.VideoWriter(f'media/output_{n-split_frame}.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height))\n",
    "        out2 = cv2.VideoWriter(f'media/output_{n-split_frame}_binary.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height), isColor=False)\n",
    "        out3 = cv2.VideoWriter(f'media/output_{n-split_frame}_clean.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 10, (frame_width, frame_height), isColor=False)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, n)\n",
    "        pred_bbox = []\n",
    "\n",
    "        for _ in range(n, min(n+100, frame_count)):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            if adaptative:\n",
    "                bbox, binary, clean, mean, variance = process_frame_adaptative(frame, mean, variance, alpha, rho)\n",
    "            else:\n",
    "                bbox, binary, clean = process_frame(frame, mean, variance, alpha)\n",
    "            \n",
    "            pred_bbox.append(bbox)\n",
    "            out2.write(binary)\n",
    "            out3.write(clean)\n",
    "\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, n)\n",
    "        for i, _ in enumerate(pred_bbox):\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            for rect in pred_bbox[i]:\n",
    "                cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (0, 0, 255), 2)\n",
    "            # Assuming gt_bbox is defined elsewhere and accessible here\n",
    "            for rect in gt_bbox[n + i - split_frame]:\n",
    "                cv2.rectangle(frame, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
    "\n",
    "            out.write(frame)\n",
    "        m = mAP(gt_bbox[(n - split_frame):(min(n+100, frame_count)- split_frame)], pred_bbox)\n",
    "        mAPs.append(m)\n",
    "        \n",
    "        out.release()\n",
    "        out2.release()\n",
    "        out3.release()\n",
    "\n",
    "    cap.release()\n",
    "    return mAPs\n",
    "\n",
    "mean_mAPs = []\n",
    "for rho in [0.05, 0.1, 0.2, 0.3, 0.4]:\n",
    "    for alpha in [2, 3, 4, 5]:\n",
    "        print(f'Alpha: {alpha}')\n",
    "        print(f'Rho: {rho}')\n",
    "        mean_mAPs.append(np.mean(process_video('data/S03/c010/vdo.avi', split_frame, frame_count, mean, variance, gt_bbox, alpha, rho, adaptative=True)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
