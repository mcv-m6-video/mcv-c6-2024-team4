{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pyflow.pyflow as pyflow\n",
    "import numpy as np\n",
    "from evaluation import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code imported from https://github.com/mcv-m6-video/mcv-m6-2023-team2/blob/main/week4/utils_w4.py\n",
    "def convert_optical_flow_to_image(flow):\n",
    "    # The 3-channel uint16 PNG images that comprise optical flow maps contain information\n",
    "    # on the u-component in the first channel, the v-component in the second channel,\n",
    "    # and whether a valid ground truth optical flow value exists for a given pixel in the third channel.\n",
    "    # A value of 1 in the third channel indicates the existence of a valid optical flow value\n",
    "    # while a value of 0 indicates otherwise. To convert the u- and v-flow values from\n",
    "    # their original uint16 format to floating point values, one can do so by subtracting 2^15 from the value,\n",
    "    # converting it to float, and then dividing the result by 64.\n",
    "\n",
    "    img_u = (flow[:, :, 2] - 2 ** 15) / 64\n",
    "    img_v = (flow[:, :, 1] - 2 ** 15) / 64\n",
    "\n",
    "    assert (flow[:, :, 0] > 1).sum() == 0 # all values are 0 or 1\n",
    "\n",
    "    img_u[flow[:, :, 0] == 0] = 0\n",
    "    img_v[flow[:, :, 0] == 0] = 0\n",
    "\n",
    "    optical_flow = np.dstack((img_u, img_v, flow[:, :, 0]))\n",
    "    return optical_flow\n",
    "\n",
    "gt_flow = cv2.imread(r'kitti_data\\training\\flow_noc\\000045_10.png', cv2.IMREAD_UNCHANGED).astype(np.double)\n",
    "gt_flow_img = convert_optical_flow_to_image(gt_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = cv2.imread(r'kitti_data\\training\\image_0\\000045_10.png').astype(float)  / 255\n",
    "second = cv2.imread(r'kitti_data\\training\\image_0\\000045_11.png').astype(float) / 255\n",
    "\n",
    "# alphas = [0.005, 0.01, 0.05, 0.1]\n",
    "# ratios = [0.25, 0.5, 0.75, 0.9]\n",
    "# minWidths = [5, 10, 30]\n",
    "# nOuterFPIterations_list = [3, 7, 11]\n",
    "# nInnerFPIterations_list = [1, 5, 9]\n",
    "# nSORIterations_list = [30, 70]\n",
    "\n",
    "alpha = 0.01\n",
    "ratio = 0.5\n",
    "minWidth = 30\n",
    "nOuterFPIterations = 7\n",
    "nInnerFPIterations = 1\n",
    "nSORIterations = 30\n",
    "\n",
    "u, v, im2W = pyflow.coarse2fine_flow(first, second, alpha, ratio, minWidth, nOuterFPIterations, nInnerFPIterations, nSORIterations)\n",
    "\n",
    "pred_flow = np.dstack((u, v, np.ones_like(u)))\n",
    "\n",
    "msen, pepn = compute_errors(gt_flow_img, pred_flow, 3, 'results_pyflow/', plots=True)\n",
    "opticalFlow_arrows(first, gt_flow_img, pred_flow, 'results_pyflow/', 'pyflow')\n",
    "HSVOpticalFlow2(gt_flow_img, 'results_pyflow/', 'pyflow_gt')\n",
    "HSVOpticalFlow2(pred_flow, 'results_pyflow/', 'pyflow_pred')\n",
    "print('MSEN:', msen)\n",
    "print('PEPN:', pepn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = cv2.imread(r'kitti_data\\training\\image_0\\000045_10.png')\n",
    "second = cv2.imread(r'kitti_data\\training\\image_0\\000045_11.png')\n",
    "first_gray = cv2.cvtColor(first, cv2.COLOR_BGR2GRAY)\n",
    "second_gray = cv2.cvtColor(second, cv2.COLOR_BGR2GRAY)\n",
    "# Assuming prev_gray is your previous grayscale image\n",
    "h, w = first_gray.shape\n",
    "\n",
    "# Create a grid of points\n",
    "y, x = np.mgrid[0:h, 0:w].astype(np.float32)\n",
    "points = np.stack((x, y), axis=-1).reshape(-1, 1, 2)\n",
    "\n",
    "new_points, status, error = cv2.calcOpticalFlowPyrLK(first_gray, second_gray, points, None, maxLevel=3, winSize=(45,45))\n",
    "\n",
    "# Create a mask to select good points\n",
    "new_points[status == 0] = 0\n",
    "points[status == 0] = 0\n",
    "\n",
    "flow = new_points - points\n",
    "\n",
    "u = flow[:, 0, 0].reshape(h, w)\n",
    "v = flow[:, 0, 1].reshape(h, w)\n",
    "\n",
    "pred_flow = np.stack((u, v, np.ones_like(u)), axis=2)\n",
    "\n",
    "msen, pepn = compute_errors(gt_flow_img, pred_flow, 3, 'results_kl/', plots=True)\n",
    "opticalFlow_arrows(first, gt_flow_img, pred_flow, 'results_kl/', 'kl')\n",
    "HSVOpticalFlow2(pred_flow, 'results_kl/', 'kl_pred')\n",
    "print('MSEN:', msen)\n",
    "print('PEPN:', pepn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.raft import RAFT\n",
    "from core.utils.utils import InputPadder\n",
    "import torch\n",
    "\n",
    "def load_image(img):\n",
    "    img = np.array(img).astype(np.uint8)\n",
    "    img = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "    return img[None]\n",
    "\n",
    "import argparse\n",
    "\n",
    "# Define a function to create and parse arguments\n",
    "def create_args(small):\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--small', action='store_true', help='use small model', default=small)\n",
    "    parser.add_argument('--mixed_precision', action='store_true', help='use mixed precision')\n",
    "    args, unknown = parser.parse_known_args()  # This line parses the arguments\n",
    "    return args\n",
    "\n",
    "# Create an 'args' variable with default values or specified values.\n",
    "args = create_args(small=False)\n",
    "\n",
    "first = cv2.imread(r'kitti_data\\training\\image_0\\000045_10.png')\n",
    "second = cv2.imread(r'kitti_data\\training\\image_0\\000045_11.png')\n",
    "\n",
    "shape = first.shape\n",
    "\n",
    "image1 = load_image(first)\n",
    "image2 = load_image(second)\n",
    "\n",
    "model = torch.nn.DataParallel(RAFT(args))\n",
    "model.load_state_dict(torch.load('raft-kitti.pth', map_location=torch.device('cpu')))\n",
    "model.eval()\n",
    "\n",
    "padder = InputPadder(image1.shape)\n",
    "image1, image2 = padder.pad(image1, image2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    flow_low, flow_up = model(image1, image2, iters=20, test_mode=True)\n",
    "\n",
    "# Resize flow_up to original image1 size\n",
    "flow_up = torch.nn.functional.interpolate(flow_up, size=shape[:2], mode='bilinear', align_corners=True)\n",
    "flow_up = flow_up.numpy().squeeze().transpose(1, 2, 0)\n",
    "\n",
    "pred_flow = np.stack((flow_up[:, :, 0], flow_up[:, :, 1], np.ones_like(flow_up[:, :, 0])), axis=2)\n",
    "msen, pepn = compute_errors(gt_flow_img, pred_flow, 3, 'results_raft/', plots=True)\n",
    "opticalFlow_arrows(first, gt_flow_img, pred_flow, 'results_raft/', 'raft')\n",
    "HSVOpticalFlow2(pred_flow, 'results_raft/', 'raft_pred')\n",
    "print('MSEN:', msen)\n",
    "print('PEPN:', pepn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
